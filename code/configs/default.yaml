training:
  model_dir: ./models
  batch_size: 64
  epochs: 100
  num_exits: 16384
  learning_rate: 0.001
  optimizer: adam
  weight_decay: 0.0001
  checkpoints: true
  checkpoint_frequency: 5
  checkpoint_dir: ./models/checkpoints

walkers:
  time_step: 0.01

hardware:
  cuda: true

model:
  name: "feed-forward"
  input_size: 2
  hidden_size: [64, 64, 64, 64] 
  output_size: 1
